# GPU 설정
CUDA_VISIBLE_DEVICES=0,1,2,3 #nvidia-smi에 나오는 사용할 gpu의 인덱스를 작성
TENSOR_PARALLEL_SIZE=4       #visible devices와 갯수맞추기
GPU_MEMORY_UTILIZATION=0.90  #보통 90%, vram이 부담되면 80~85

# CPU/스레드 설정
OMP_NUM_THREADS=32 #가능한 스레드 갯수의 1/4정도(발열관리 목적)로 시작해서 cpu온도 모니터링 하면서 서서히 올려봄
MKL_NUM_THREADS=32 #마찬가지
OMP_PROC_BIND=true #process를 쓰레드에 고정해서, 안정성을 높힘. close|false|spread|master 가능
OMP_PLACES=cores   #각 OpenMP 스레드를 물리적 CPU 코어에 고정(bind)하라는 의미
TASKSET_CPUS=0-63 #발열관리의 핵심지표, 물리적으로 사용할 코어의 인덱스를 전달

# NCCL 설정
NCCL_DEBUG=WARN
NCCL_P2P_DISABLE=0
NCCL_IB_DISABLE=1

# vLLM 최적화 설정
VLLM_SLEEP_WHEN_IDLE=1 #사용하지 않을때 cpu온도와 gpu온도를 낮출 수 있으나, idle상태에서 깨어날때 성능에 딜레이가 있음
VLLM_TUNE_FUSED_MOE=1 #MOE를 사용하는 모델(qwen, deepseek)에 맞춰진 최적화 옵션

# 모델 설정
MODEL_NAME=Qwen/Qwen3-235B-A22B-Instruct-2507-FP8
MAX_NUM_SEQS=64
MAX_NUM_BATCHED_TOKENS=98304
MAX_MODEL_LEN=131072

# 서버 설정
VLLM_PORT=8000